{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fqpaVy5IRwJM"
   },
   "source": [
    "# Hate Speech and Offensive Language Detection\n",
    "This notebook runs our experiments on the Hate Speech and Offensive Language Detection tweet dataset.\n",
    "WARNING: dataset contains offensive language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmjrIyVlbO44"
   },
   "source": [
    "##  AAE detection model\n",
    "As described in our paper, we use the model from https://github.com/slanglab/twitteraae to detect the dialect of each tweet, we only need the model files from the repo which we have conveniently copied in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "Uk4UtaGhbbxt",
    "outputId": "87575ecf-058f-4db2-ac66-5781ed095e98"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import time\n",
    "import random\n",
    "vocabfile = \"twitteraae_models/model_vocab.txt\" # change path if needed, path inside twitteraae repo is twitteraae/model/model_vocab.txt\n",
    "modelfile = \"twitteraae_models/model_count_table.txt\" # change path if needed, path inside twitteraae repo is twitteraae/model/model_vocab.txt\n",
    "\n",
    "# the following functions are copied from twitteraae for convenience\n",
    "K=0; wordprobs=None; w2num=None\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Idempotent\"\"\"\n",
    "    global vocab,w2num,N_wk,N_k,wordprobs,N_w,K, modelfile,vocabfile\n",
    "    if wordprobs is not None:\n",
    "        # assume already loaded\n",
    "        return\n",
    "\n",
    "    N_wk = np.loadtxt(modelfile)\n",
    "    N_w = N_wk.sum(1)\n",
    "    N_k = N_wk.sum(0)\n",
    "    K = len(N_k)\n",
    "    wordprobs = (N_wk + 1) / N_k\n",
    "\n",
    "    vocab = [L.split(\"\\t\")[-1].strip() for L in open(vocabfile,encoding=\"utf8\")]\n",
    "    w2num = {w:i for i,w in enumerate(vocab)}\n",
    "    assert len(vocab) == N_wk.shape[0]\n",
    "\n",
    "def infer_cvb0(invocab_tokens, alpha, numpasses):\n",
    "    global K,wordprobs,w2num\n",
    "    doclen = len(invocab_tokens)\n",
    "\n",
    "    # initialize with likelihoods\n",
    "    Qs = np.zeros((doclen, K))\n",
    "    for i in range(0,doclen):\n",
    "        w = invocab_tokens[i]\n",
    "        Qs[i,:] = wordprobs[w2num[w],:]\n",
    "        Qs[i,:] /= Qs[i,:].sum()\n",
    "    lik = Qs.copy()  # pertoken normalized but proportionally the same for inference\n",
    "\n",
    "    Q_k = Qs.sum(0)\n",
    "    for itr in range(1,numpasses):\n",
    "        # print \"cvb0 iter\", itr\n",
    "        for i in range(0,doclen):\n",
    "            Q_k -= Qs[i,:]\n",
    "            Qs[i,:] = lik[i,:] * (Q_k + alpha)\n",
    "            Qs[i,:] /= Qs[i,:].sum()\n",
    "            Q_k += Qs[i,:]\n",
    "\n",
    "    Q_k /= Q_k.sum()\n",
    "    return Q_k\n",
    "\n",
    "def predict_lang(tokens, alpha=1, numpasses=5, thresh1=1, thresh2=0.2):\n",
    "    invocab_tokens = [w.lower() for w in tokens if w.lower() in w2num]\n",
    "    # check that at least xx tokens are in vocabulary\n",
    "    if len(invocab_tokens) < thresh1:\n",
    "        return None  \n",
    "    # check that at least yy% of tokens are in vocabulary\n",
    "    elif len(invocab_tokens) / len(tokens) < thresh2:\n",
    "        return None\n",
    "    else:\n",
    "        posterior = infer_cvb0(invocab_tokens, alpha=alpha, numpasses=numpasses)\n",
    "        return posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the twitteraae model for detection\n",
    "load_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKn4AL_cRwJo"
   },
   "source": [
    "We load the dataset 'labeled_data.csv', available at https://github.com/t-davidson/hate-speech-and-offensive-language, for convenience we copy it to this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Juu5hXhbRy7"
   },
   "outputs": [],
   "source": [
    "# for cnn\n",
    "\n",
    "labeled_data_path = \"data/labeled_data.csv\" # change path if needed\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy', batch_first = True)\n",
    "LABEL = data.LabelField(dtype = torch.long, sequential=False, use_vocab=False)\n",
    "EXPERT = data.LabelField(dtype = torch.long,  sequential=False, use_vocab=False)\n",
    "GROUP = data.LabelField(dtype = torch.long, sequential=False, use_vocab=False)\n",
    "EXPERTLABEL = data.LabelField(dtype = torch.long, sequential=False, use_vocab=False)\n",
    "\n",
    "fields = [(None, None),(None, None),('expertlabel', EXPERTLABEL),('group', GROUP),('expert', EXPERT),\n",
    "          ('label', LABEL), ('text', TEXT)]\n",
    "\n",
    "train_data_orig = data.TabularDataset.splits(\n",
    "                                        path = '',\n",
    "                                        train = labeled_data_path,\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cf20Ut32oPCd"
   },
   "source": [
    "Augment data with expert predictions and demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "pYfTDftioZBu",
    "outputId": "8e991090-054a-440a-ef1c-21d98b3996fb"
   },
   "outputs": [],
   "source": [
    "# build expert data\n",
    "all_data = train_data_orig[0]\n",
    "\n",
    "p = 0.75 # expert probability of being correct for AA tweeet\n",
    "q = 0.9 # expert probability of being correct for AA tweeet\n",
    "\n",
    "# tracker variables for statistics\n",
    "sum = 0\n",
    "total = 0\n",
    "i = 0\n",
    "aa_frac = 0\n",
    "for example in all_data:\n",
    "    lang = predict_lang(vars(example)['text'])\n",
    "    aa = 0\n",
    "    try:\n",
    "        if lang[0] >= 0.5:\n",
    "            aa = 1\n",
    "    except:\n",
    "        print(\"error processing tweet: \"+str(vars(example)['text']))\n",
    "    label = vars(example)['label']\n",
    "    exp = 0 # 0: expert wrong, 1: expert is right\n",
    "    exp_label = 0\n",
    "    if aa == 1: # if tweet is african american\n",
    "\n",
    "        coin = np.random.binomial(1,p)\n",
    "        if coin:\n",
    "            exp =1 \n",
    "            exp_label = np.long(label)\n",
    "        else:\n",
    "            exp_label = np.long(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    else:\n",
    "        coin = np.random.binomial(1,q)\n",
    "        if coin:\n",
    "            exp =1 # is right 90% of time\n",
    "            exp_label = np.long(label)\n",
    "        else:\n",
    "            exp_label = np.long(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    #if label =='2' : # 2: neither, 1: offensive, 0: hate speech\n",
    "    #    aa = 1\n",
    "    vars(all_data[i])['expertlabel'] = exp_label\n",
    "    vars(all_data[i])['group'] = str(aa)\n",
    "    vars(all_data[i])['expert'] = exp\n",
    "    aa_frac += aa\n",
    "    i += 1\n",
    "    total +=1\n",
    "    sum += exp\n",
    "#print(sum/total)\n",
    "#print(aa_frac/total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data for Pytorch and vectorize, this requires the glove.6b.100d embeddings which will be downloaded (862mb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LABEL.build_vocab(all_data)\n",
    "EXPERT.build_vocab(all_data)\n",
    "GROUP.build_vocab(all_data)\n",
    "EXPERTLABEL.build_vocab(all_data)\n",
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(all_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data for train, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLKxaqpIRwJ4"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data, valid_data  = all_data.split(split_ratio=[0.6,0.1,0.3])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    sort = False,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is of two parts:\n",
    "1) the first part goes through our method and baselines to get results\n",
    "2) the second combines all models to get std and confidence intervals, but need to go through the first part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZLZocE7ggnm"
   },
   "source": [
    "# Build model\n",
    "Model definitions for sentiment analysis adapted from https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMT9UoiigZhS"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[0], embedding_dim))\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[1], embedding_dim))\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[2], embedding_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "        conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        out = self.fc(cat)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "class CNN_rej(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.embedding_rej = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs_rej = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc_rej = nn.Linear(len(filter_sizes) * n_filters, 1)\n",
    "        \n",
    "        self.dropout_rej = nn.Dropout(dropout)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        embedded_rej = self.embedding_rej(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded_rej = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved_rej = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs_rej]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled_rej = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat_rej = self.dropout_rej(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        out_rej = self.fc_rej(cat_rej)\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        out = self.fc(cat)\n",
    "        out =  torch.cat((out, out_rej), 1)\n",
    "\n",
    "        out = self.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100 # fixed\n",
    "N_FILTERS = 300 # hyperparameterr\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 4\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "#model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "model = CNN_rej(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 3, DROPOUT, PAD_IDX)\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hs2N0LRbRwKb"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHXr-a2ARwKf"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "usU7JU75RwKp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
    "def reject_CrossEntropyLoss(outputs, m, labels, m2, n_classes):\n",
    "    '''\n",
    "    The L_{CE} loss implementation for hatespeech, identical to CIFAR implementation\n",
    "    ----\n",
    "    outputs: network outputs\n",
    "    m: cost of deferring to expert cost of classifier predicting (I_{m =y})\n",
    "    labels: target\n",
    "    m2:  cost of classifier predicting (alpha* I_{m\\neq y} + I_{m =y})\n",
    "    n_classes: number of classes\n",
    "    '''\n",
    "    batch_size = outputs.size()[0]            # batch_size\n",
    "    rc = [n_classes] * batch_size\n",
    "    rc = torch.tensor(rc)\n",
    "    outputs =  -m*torch.log2( outputs[range(batch_size), rc]) - m2*torch.log2(outputs[range(batch_size), labels])   # pick the values corresponding to the labels\n",
    "    return torch.sum(outputs)/batch_size\n",
    "\n",
    "def train_reject(model, iterator, optimizer,alpha):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text)\n",
    "        batch_size = predictions.size()[0]\n",
    "        # get expert predictions and costs \n",
    "        m = (batch.expert)*1.0 # expert agreement with label: I_{m=y}\n",
    "        m2 = [1] * batch_size\n",
    "        m2 = torch.tensor(m2)\n",
    "        for j in range (0,batch_size):\n",
    "            exp = m[j].item()\n",
    "            if exp:\n",
    "                m2[j] = alpha\n",
    "            else:\n",
    "                m2[j] = 1\n",
    "\n",
    "        m2 = m2.to(device)\n",
    "\n",
    "        loss = reject_CrossEntropyLoss(predictions, m, batch.label, m2, 3)\n",
    "\n",
    "        acc = categorical_accuracy(predictions, batch.label.to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "def evaluate_reject(model, iterator):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text)\n",
    "            batch_size = predictions.size()[0]            # batch_size\n",
    "            m = batch.expert\n",
    "            m2 = [1] * batch_size\n",
    "            m2 = torch.tensor(m2)\n",
    "            m2 = m2.to(device)\n",
    "            loss = reject_CrossEntropyLoss(predictions, m, batch.label, m2, 3)\n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbfpfCHA0UNe"
   },
   "outputs": [],
   "source": [
    "def metrics_print(net, loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs = net(data.text)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = (predicted[i].item() == 3)\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp +=  data.expert[i].item()\n",
    "                    correct_sys += data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "def metrics_print_fairness(net, loader):\n",
    "    net.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs = net(data.text)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = (predicted[i].item() == 3)\n",
    "                prediction = 0\n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "\n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvNc3f0YRwK-"
   },
   "source": [
    "Train the model by validation over alpha in [0,1] with steps of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "colab_type": "code",
    "id": "IapphlTjRwLD",
    "outputId": "66727958-0c5a-4f5d-e9ed-d16dc76cec25"
   },
   "outputs": [],
   "source": [
    "import copy, time \n",
    "for i in range(0,11):\n",
    "    model = CNN_rej(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 3, DROPOUT, PAD_IDX)\n",
    "\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    alpha = i/10\n",
    "    N_EPOCHS = 5\n",
    "\n",
    "    best_valid_loss = 0\n",
    "    best_model = None\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = train_reject(model, train_iterator, optimizer, alpha)\n",
    "\n",
    "        valid_loss = metrics_print(model,valid_iterator)[1]\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss >= best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "    \n",
    "\n",
    "    print(metrics_print(best_model, valid_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_print_fairness(best_model, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_print(best_model, test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gL9zMseKV08"
   },
   "source": [
    "# Baseline: Confidence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTpVIBmaTd0F"
   },
   "outputs": [],
   "source": [
    "class CNN_(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        out = self.fc(cat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4DW24ej8Kiog"
   },
   "source": [
    "## expert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wa26cku4KXn_"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 300\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 2\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model_expert = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 2, DROPOUT, PAD_IDX)\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model_expert.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model_expert.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model_expert.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xI84VYA_Kovo"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model_expert.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_expert = model_expert.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpLZVhleKrd6"
   },
   "outputs": [],
   "source": [
    "def train_expert(model_exp, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model_exp.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model_exp(batch.text)\n",
    "\n",
    "        \n",
    "        loss = criterion(predictions, batch.expert)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.expert)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate_expert(model_exp, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_exp.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model_exp(batch.text)\n",
    "            loss = criterion(predictions, batch.expert)\n",
    "            acc = categorical_accuracy(predictions, batch.expert)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "colab_type": "code",
    "id": "I0P9v_fnKu8x",
    "outputId": "bc853ec7-c1b7-4430-d138-d4ed12771bd8"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_expert(model_expert, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate_expert(model_expert, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_expert.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2UHAGm-QW-I"
   },
   "source": [
    "## classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "meGJ9JJXQKMo"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 300\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 3\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model_class = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model_class.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model_class.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model_class.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model_class.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_class = model_class.to(device)\n",
    "criterion = criterion.to(device)\n",
    "def train(model_class, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model_class.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model_class(batch.text)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "def evaluate(model_class, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_class.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model_class(batch.text)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "vDJ68oaoQi3v",
    "outputId": "56617497-e5ef-4955-bf1d-f00109752210"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model_class, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model_class, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_class.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VtNZ4bMAT2_8"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "def metrics_print_confid(net_class, net_exp, loader):\n",
    "    net_class.eval()\n",
    "    net_exp.eval()\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            outputs_exp = net_exp(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                r_score = 1 - np.max(arr) #outputs_class.data[i][predicted[i].item()].item()\n",
    "                arr_exp = [outputs_exp.data[i][0].item(),outputs_exp.data[i][1].item()]\n",
    "                arr_exp = softmax(arr_exp)\n",
    "                r_score = r_score - arr_exp[0]\n",
    "                r = 0\n",
    "                if r_score >= 0:\n",
    "                    r = 1\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp +=  data.expert[i].item()\n",
    "                    correct_sys +=  data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "\n",
    "def metrics_print_confid_fairness(net_class, net_exp, loader):\n",
    "    net_class.eval()\n",
    "    net_exp.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            outputs_exp = net_exp(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                r_score = 1 - np.max(arr) #outputs_class.data[i][predicted[i].item()].item()\n",
    "                arr_exp = [outputs_exp.data[i][0].item(),outputs_exp.data[i][1].item()]\n",
    "                arr_exp = softmax(arr_exp)\n",
    "                r_score = r_score - arr_exp[0]\n",
    "                r = 0\n",
    "                if r_score >= 0:\n",
    "                    r = 1\n",
    "                prediction = 0\n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "    print(group_1_counts)\n",
    "    print(group_0_counts)\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    print(to_print)\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "M5sUm1NgVZrY",
    "outputId": "8e1ea87e-49af-4068-d7d7-9b73c98ef791"
   },
   "outputs": [],
   "source": [
    "metrics_print_confid(model_class, model_expert,test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics_print_confid_fairness(model_class, model_expert,test_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YzzfbXZ6aJH"
   },
   "source": [
    "# Oracle Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJf-zDG46cbU"
   },
   "outputs": [],
   "source": [
    "def metrics_print_oracle(net_class, loader):\n",
    "    # prints classification metrics for Oracle baseline\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= 0.90:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= 0.75:\n",
    "                        r = 1\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp +=  data.expert[i].item()\n",
    "                    correct_sys +=  data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "def metrics_print_oracle_fairness(net_class, loader):\n",
    "    net_class.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= 0.90:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= 0.75:\n",
    "                        r = 1                \n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_print_classifier(net_class, loader):\n",
    "    # print classification metrics of the classifier alone on all the dataset\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                total += 1\n",
    "                correct += (predicted[i] == data.label[i]).item()\n",
    "                correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "\n",
    "def metrics_print_classifier_fairness(net_class, loader):\n",
    "    # print fairness metrics of the classifier alone on all the dataset\n",
    "    net_class.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                prediction = predicted[i]\n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    print(to_print)\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def metrics_print_expert_fairness( loader):\n",
    "    # print fairness metrics of the expert on all the dataset\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            batch_size =len(data)            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    print(to_print)\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_print_expert_fairness( test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_print_classifier_fairness(model_class, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "h0QDnycBFWWB",
    "outputId": "d411364e-ec6e-4a89-bf79-8eedc5e4673a"
   },
   "outputs": [],
   "source": [
    "metrics_print_oracle(model_class,test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_print_oracle_fairness(model_class,test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: repeat data building for each expert type\n",
    "the following repeats the above code many times to obtain error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# build expert data\n",
    "all_data = train_data_orig[0]\n",
    "p = 0.75 # expert probability of being correct for AA tweeet\n",
    "q = 0.9 # expert probability of being correct for AA tweeet\n",
    "sum = 0\n",
    "total = 0\n",
    "i = 0\n",
    "aa_frac = 0\n",
    "for example in all_data:\n",
    "    lang = predict_lang(vars(example)['text'])\n",
    "    aa = 0\n",
    "    try:\n",
    "        if lang[0] >= 0.5:\n",
    "            aa = 1\n",
    "    except:\n",
    "        print(vars(example)['text'])\n",
    "    label = vars(example)['label']\n",
    "    exp = 0 # 0: expert wrong, 1: expert is right\n",
    "    exp_label = 0\n",
    "    if aa == 1: # if tweet is african american\n",
    "        #if label == '2':\n",
    "        #    exp = 0 # never predict neither\n",
    "        #else:\n",
    "        coin = np.random.binomial(1,p) \n",
    "        if coin:\n",
    "            exp =1 # is right 90% of time\n",
    "            exp_label = np.long(label)\n",
    "        else:\n",
    "            exp_label = np.long(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    else:\n",
    "        coin = np.random.binomial(1,q)\n",
    "        if coin:\n",
    "            exp =1 # is right 90% of time\n",
    "            exp_label = np.long(label)\n",
    "        else:\n",
    "            exp_label = np.long(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    #if label =='2' : # 2: neither, 1: offensive, 0: hate speech\n",
    "    #    aa = 1\n",
    "    vars(all_data[i])['expertlabel'] = exp_label\n",
    "    vars(all_data[i])['group'] = str(aa)\n",
    "    vars(all_data[i])['expert'] = exp\n",
    "    aa_frac += aa\n",
    "    i += 1\n",
    "    total +=1\n",
    "    sum += exp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, valid_data  = all_data.split(split_ratio=[0.7,0.2,0.1])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    sort = False,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be changed for each expert model\n",
    "def metrics_print_oracle(net_class, loader):\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= q:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= p:\n",
    "                        r = 1\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp +=  data.expert[i].item()\n",
    "                    correct_sys +=  data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "def metrics_print_oracle_fairness(net_class, loader):\n",
    "    net_class.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= q:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= p:\n",
    "                        r = 1                \n",
    "                \n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_conf = []\n",
    "exp_rej = []\n",
    "exp_ora = []\n",
    "exp_conf_fairness = []\n",
    "exp_rej_fairness = []\n",
    "exp_ora_fairness = []\n",
    "max_trials = 1\n",
    "for exp in range(0,max_trials):\n",
    "    train_data, test_data, valid_data  = all_data.split(split_ratio=[0.6,0.1,0.3])\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data), \n",
    "        sort = False,\n",
    "        batch_size = BATCH_SIZE, \n",
    "        device = device)\n",
    "    ##################################################################################################\n",
    "    ##################################################################################################\n",
    "    # baseline confidence\n",
    "    ##################################################################################################\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = 100\n",
    "    N_FILTERS = 300\n",
    "    FILTER_SIZES = [3,4,5]\n",
    "    OUTPUT_DIM = 2\n",
    "    DROPOUT = 0.5\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model_expert = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 2, DROPOUT, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model_expert.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model_expert.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model_expert.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    optimizer = optim.Adam(model_expert.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model_expert = model_expert.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = 5\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train_expert(model_expert, train_iterator, optimizer, criterion)\n",
    "        #valid_loss, valid_acc = evaluate_expert(model_expert, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # classifier\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = 100\n",
    "    N_FILTERS = 300\n",
    "    FILTER_SIZES = [3,4,5]\n",
    "    OUTPUT_DIM = 3\n",
    "    DROPOUT = 0.5\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model_class = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model_class.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model_class.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model_class.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    optimizer = optim.Adam(model_class.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model_class = model_class.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = 5\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model_class, train_iterator, optimizer, criterion)\n",
    "        #valid_loss, valid_acc = evaluate(model_class, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    ####################################\n",
    "    print(\"Baseline\")\n",
    "    \n",
    "    conf = metrics_print_confid(model_class, model_expert,test_iterator)\n",
    "    exp_conf.append(conf)\n",
    "    conf = metrics_print_confid_fairness(model_class, model_expert,test_iterator)\n",
    "    exp_conf_fairness.append(conf)\n",
    "    ##################################################################################################\n",
    "    # my method \n",
    "    ##################################################################################################\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = 100\n",
    "    N_FILTERS = 1000\n",
    "    FILTER_SIZES = [3,4,5]\n",
    "    OUTPUT_DIM = 4\n",
    "    DROPOUT = 0.5\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 4, DROPOUT, PAD_IDX)\n",
    "\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    N_EPOCHS = 15\n",
    "\n",
    "    best_valid_loss = 0\n",
    "    best_model = None\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = train_reject(model, train_iterator, optimizer, 1)\n",
    "        #train_loss, train_acc = train_reject_bla(model, train_iterator, optimizer)\n",
    "\n",
    "        #valid_loss, valid_acc = evaluate_reject(model, valid_iterator)\n",
    "        valid_loss = metrics_print(model,valid_iterator)[1]\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss >= best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "    \n",
    "    print(\"Our method\")\n",
    "    rej = metrics_print(best_model, test_iterator)\n",
    "    exp_rej.append(rej)\n",
    "    print(rej)\n",
    "    rej = metrics_print_fairness(best_model, test_iterator)\n",
    "    exp_rej_fairness.append(rej)\n",
    "    ##############################################################################################\n",
    "    # ORACLE\n",
    "    ora = metrics_print_oracle(model_class, test_iterator)\n",
    "    print(ora)\n",
    "    exp_ora.append(ora)\n",
    "    ora = metrics_print_oracle_fairness(model_class, test_iterator)\n",
    "    exp_ora_fairness.append(ora)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_class = [\"coverage\", \"system accuracy\", \"expert accuracy\", \"classifier accuracy\"]\n",
    "metrics_fairness = [\"FPR for group 0\", \"FPR for group 1\", \"discrimination\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for Confidence Baseline\")\n",
    "for i in range(0,4):\n",
    "    print(\"----\")\n",
    "    print(\"For \" + metrics_class[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_conf[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n",
    "print(\"#############################\")\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(\"-----\")\n",
    "    print(\"For \" + metrics_fairness[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_conf_fairness[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for Oracle Baseline\")\n",
    "for i in range(0,4):\n",
    "    print(\"----\")\n",
    "    print(\"For \" + metrics_class[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_ora[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n",
    "print(\"#############################\")\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(\"-----\")\n",
    "    print(\"For \" + metrics_fairness[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_ora_fairness[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for our method L_{CE}\")\n",
    "\n",
    "for i in range(0,4):\n",
    "    print(\"----\")\n",
    "    print(\"For \" + metrics_class[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_rej[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n",
    "print(\"#############################\")\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(\"-----\")\n",
    "    print(\"For \" + metrics_fairness[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_rej_fairness[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hatespeech - Faster Sentiment Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
